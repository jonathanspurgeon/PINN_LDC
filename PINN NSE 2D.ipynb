{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../Utilities/')\n",
    "\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"gpu\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class SineLayer(torch.nn.Module):\n",
    "    def __init__(self, w0):\n",
    "        super(SineLayer, self).__init__()\n",
    "        self.w0 = w0    # this is the frequency of the sine wave\n",
    "\n",
    "    def forward(self,x):\n",
    "        return torch.sin(self.w0*x)\n",
    "    \n",
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        # set up layer order dict\n",
    "        # self.activation = SineLayer(3)\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, SineLayer(3)))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the physics-guided neural network\n",
    "def calc_grad(y, x) -> torch.Tensor:\n",
    "        grad = torch.autograd.grad(\n",
    "            outputs=y,\n",
    "            inputs=x,\n",
    "            grad_outputs=torch.ones_like(y),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )[0]\n",
    "        return grad\n",
    "\n",
    "        \n",
    "class PhysicsInformedNN():\n",
    "    def __init__(self, X, u, Xt, X_i, X_f, layers):\n",
    "    \n",
    "        \n",
    "        # data\n",
    "        self.x = torch.tensor(X[:, 0], requires_grad=True).float().to(device)\n",
    "        self.y = torch.tensor(X[:, 1], requires_grad=True).float().to(device)\n",
    "        self.t = torch.tensor(X[:, 2], requires_grad=True).float().to(device)\n",
    "        self.u = torch.tensor(u).float().to(device)\n",
    "\n",
    "\n",
    "        self.x_lr = torch.tensor(X_f[:, 0], requires_grad=True).float().to(device)\n",
    "        self.y_lr = torch.tensor(X_f[:, 1], requires_grad=True).float().to(device)\n",
    "        self.t_lr = torch.tensor(X_f[:, 2], requires_grad=True).float().to(device)\n",
    "\n",
    "        self.x_tb = torch.tensor(X_i[:, 0], requires_grad=True).float().to(device)\n",
    "        self.y_tb = torch.tensor(X_i[:, 1], requires_grad=True).float().to(device)\n",
    "        self.t_tb = torch.tensor(X_i[:, 2], requires_grad=True).float().to(device)\n",
    "        \n",
    "        self.x_t = torch.tensor(Xt[:, 0], requires_grad=True).float().to(device)\n",
    "        self.y_t = torch.tensor(Xt[:, 1], requires_grad=True).float().to(device)\n",
    "        self.t_t = torch.tensor(Xt[:, 2], requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.dnn.parameters(), \n",
    "            lr=1.0, \n",
    "            max_iter=50000, \n",
    "            max_eval=50000, \n",
    "            history_size=50,\n",
    "            tolerance_grad=1e-6, \n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            line_search_fn=\"strong_wolfe\"    \n",
    "        )\n",
    "        \n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters())\n",
    "        \n",
    "    def net_u(self, x, y, t):  \n",
    "        u = self.dnn(torch.stack([x, y, t], dim=1))\n",
    "        return u\n",
    "    \n",
    "    def RH_l(self, p1, p2, u1, u2, v1, v2):\n",
    "        if torch.norm(p1 - p2) > 0.2 and torch.norm((u1-u2)**2+(v1-v2)**2) > 0.04:\n",
    "            return torch.norm((p1 - p2)*((u1-u2)**2+(v1-v2)**2))\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    \n",
    "    def net_f_rh(self, x, y, t, dx, dy):\n",
    "        \n",
    "\n",
    "        gamma = 1.4\n",
    "        hidden_output = self.net_u(x, y, t)\n",
    "        hidden_output2 = self.net_u(x - dx, y, t)\n",
    "        hidden_output3 = self.net_u(x, y - dy, t)\n",
    "        rho_1 = hidden_output[:, 0]\n",
    "        u_1 = hidden_output[:, 1]\n",
    "        v_1 = hidden_output[:, 2]\n",
    "        p_1 = hidden_output[:, 3]\n",
    "        rho_2 = hidden_output2[:, 0]\n",
    "        u_2 = hidden_output2[:, 1]\n",
    "        v_2 = hidden_output2[:, 2]\n",
    "        p_2 = hidden_output2[:, 3]\n",
    "        rho_3 = hidden_output3[:, 0]\n",
    "        u_3 = hidden_output3[:, 1]\n",
    "        v_3 = hidden_output3[:, 2]\n",
    "        p_3 = hidden_output3[:, 3]\n",
    "\n",
    "        V2_1 = u_1 ** 2 + v_1 **2\n",
    "        E_1 = (p_1 / (gamma - 1)) + (1/2 * rho_1 * V2_1)\n",
    "        V2_2 = u_2 ** 2 + v_2 **2\n",
    "        E_2 = (p_2 / (gamma - 1)) + (1/2 * rho_2 * V2_2)\n",
    "        V2_3 = u_3 ** 2 + v_3 **2\n",
    "        E_3 = (p_3 / (gamma - 1)) + (1/2 * rho_3 * V2_3)\n",
    "        e_1 = E_1 - (1/2 * rho_1 * V2_1)\n",
    "        e_2 = E_2 - (1/2 * rho_2 * V2_2)\n",
    "        e_3 = E_3 - (1/2 * rho_3 * V2_3)\n",
    "        \n",
    "        f_1_x = rho_1*rho_2*((u_1 - u_2) ** 2 + (v_1 - v_2) ** 2) - (p_1 - p_2)*(rho_1 - rho_2)\n",
    "        f_2_x = e_1*rho_2 + rho_1*e_2 - (1/2*(p_1 + p_2)*(rho_1 - rho_2))\n",
    "        f_1_y = rho_1*rho_3*((u_1 - u_3) ** 2 + (v_1 - v_3) ** 2) - (p_1 - p_3)*(rho_1 - rho_3)\n",
    "        f_2_y = e_1*rho_3 + rho_1*e_3 - (1/2*(p_1 + p_3)*(rho_1 - rho_3))\n",
    "        l_x = self.RH_l(p_1, p_2, u_1, u_2, v_1, v_2)\n",
    "        l_y = self.RH_l(p_1, p_3, u_1, u_3, v_1, v_3)\n",
    "        del hidden_output, rho_1, v_1, u_1, p_1, e_1, E_1, V2_1\n",
    "        del hidden_output2, rho_2, v_2, u_2, p_2, e_2, E_2, V2_2\n",
    "        del hidden_output3, rho_3, v_3, u_3, p_3, e_3, E_3, V2_3\n",
    "        return torch.mul(l_x, f_1_x), torch.mul(l_x, f_2_x), torch.mul(l_y, f_1_y), torch.mul(l_y, f_2_y)\n",
    "    \n",
    "    # def loss_con(self, x_en,x_in, t_en, t_in, crhoL,cuL,cpL,crhoR,cuR,cpR,tf):\n",
    "    #     y_en = self.net_u(x_en, t_en)                                      \n",
    "    #     y_in = self.net_u(x_in, t_in)                                     \n",
    "    #     rhoen, pen,uen = y_en[:, -1], y_en[:, 2], y_en[:, 1]         \n",
    "    #     rhoin, pin,uin = y_in[:, -1], y_in[:, 2], y_in[:, 1]         \n",
    "\n",
    "    #     U2en = 0.5*rhoen*uen**2 + pen/0.4\n",
    "    #     U2in = 0.5*rhoin*uin**2 + pin/0.4\n",
    "    #     gamma = 0.4\n",
    "    #     cU2L = 0.5*crhoL*cuL**2 + cpL/0.4 \n",
    "    #     cU2R = 0.5*crhoR*cuR**2 + cpR/0.4 \n",
    "    #     # Loss function for the initial condition\n",
    "    #     loss_en = (torch.mean(rhoen - rhoin) - tf*(crhoL*cuL-crhoR*cuR))**2+ \\\n",
    "    #         (torch.mean(-U2en+ U2in) + tf*(cU2L*cuL - cU2R*cuR) + (cpL*cuL - cpR*cuR)*tf )**2 +\\\n",
    "    #         (torch.mean(-rhoen*uen + rhoin*uin)+(cpL-cpR)*tf +(crhoL*cuL*cuL-crhoR*cuR*cuR)*tf)**2\n",
    "    #     return loss_en \n",
    "    \n",
    "    def net_f_x(self, x, y, t):\n",
    "\n",
    "        gamma = 1.4\n",
    "        hidden_output = self.net_u(x, y, t)\n",
    "        rho_pred = hidden_output[:, 0]\n",
    "        u_pred = hidden_output[:, 1]\n",
    "        v_pred = hidden_output[:, 2]\n",
    "        p_pred = hidden_output[:, 2]\n",
    "\n",
    "        rho_x = calc_grad(rho_pred, x)\n",
    "        p_x = calc_grad(p_pred, x)\n",
    "        u_x, v_x = calc_grad(u_pred, x), calc_grad(v_pred, x)\n",
    "        del rho_pred, u_pred, v_pred, p_pred, hidden_output\n",
    "        return rho_x, u_x, v_x, p_x\n",
    "    \n",
    "    def net_f_y(self, x, y, t):\n",
    "\n",
    "        gamma = 1.4\n",
    "        hidden_output = self.net_u(x, y, t)\n",
    "        rho_pred = hidden_output[:, 0]\n",
    "        u_pred = hidden_output[:, 1]\n",
    "        v_pred = hidden_output[:, 2]\n",
    "        p_pred = hidden_output[:, 2]\n",
    "\n",
    "        rho_x = calc_grad(rho_pred, y)\n",
    "        p_x = calc_grad(p_pred, y)\n",
    "        u_x, v_x = calc_grad(u_pred, y), calc_grad(v_pred, y)\n",
    "        del rho_pred, u_pred, v_pred, p_pred, hidden_output\n",
    "        return rho_x, u_x, v_x, p_x\n",
    "     \n",
    "    def net_f(self, x, y, t):\n",
    "\n",
    "        gamma = 1.4\n",
    "        hidden_output = self.net_u(x, y, t)\n",
    "        rho_pred = hidden_output[:, 0]\n",
    "        u_pred = hidden_output[:, 1]\n",
    "        v_pred = hidden_output[:, 2]\n",
    "        p_pred = hidden_output[:, 3]\n",
    "\n",
    "        V2_mag = u_pred ** 2 + v_pred ** 2\n",
    "        E_pred = (p_pred / (gamma - 1)) + (1/2 * rho_pred * V2_mag)\n",
    "        rho_t = calc_grad(rho_pred, t)\n",
    "        p_x = calc_grad(p_pred, x)\n",
    "        p_y = calc_grad(p_pred, y)\n",
    "        # u_x, v_y = calc_grad(u_pred, x), calc_grad(v_pred, y)\n",
    "        f_rho = ( \n",
    "            rho_t + calc_grad(rho_pred * u_pred, x) + calc_grad(rho_pred * v_pred, y)\n",
    "            )\n",
    "        f_u = (\n",
    "            calc_grad(rho_pred * u_pred, t) + \n",
    "            calc_grad(rho_pred * torch.square(u_pred), x) + p_x\n",
    "            + calc_grad(rho_pred * v_pred * u_pred, y)\n",
    "        )\n",
    "        f_v = (\n",
    "            calc_grad(rho_pred * v_pred, t) + calc_grad(rho_pred * torch.square(v_pred), y) + p_y\n",
    "            + calc_grad(rho_pred * v_pred * u_pred, x)\n",
    "        )\n",
    "        f_e = (\n",
    "            calc_grad(E_pred, t) +  calc_grad(u_pred * (E_pred + p_pred), x)\n",
    "            + calc_grad(v_pred * (E_pred + p_pred), y)\n",
    "        )\n",
    "        del rho_pred, u_pred, v_pred, p_pred, E_pred, hidden_output, V2_mag, rho_t, p_x, p_y\n",
    "        # l = (1/ ( 0.2*(torch.norm(u_x + v_y) - (u_x + v_y) ) + 1))\n",
    "        return f_rho, f_u, f_v, f_e\n",
    "    \n",
    "    def loss_func(self):\n",
    "        u_pred = self.net_u(self.x, self.y, self.t)\n",
    "        # rho_y_tb, u_y_tb, v_y_tb, p_y_tb = self.net_f_y(self.x_tb, self.y_tb, self.t_tb)\n",
    "        # rho_x_lr, u_x_lr, v_x_lr, p_x_lr = self.net_f_x(self.x_lr, self.y_lr, self.t_lr)\n",
    "        dx = 1/100\n",
    "        dy = 1/100\n",
    "        # loss_con = self.loss_con(self.x_en,self.x_in, self.y_en, self.y_in, 1,0,1,0.125,0,0.1,0.2)\n",
    "        f_rho_pred, f_u_pred, f_v_pred, f_e_pred = self.net_f(self.x_t, self.y_t, self.t_t)\n",
    "        f_1_x, f_2_x, f_1_y, f_2_y = self.net_f_rh(self.x_t, self.y_t, self.t_t, dx, dy)\n",
    "        loss = 10*(torch.mean((self.u[:, 0] - u_pred[:, 0]) ** 2) + torch.mean((self.u[:, 1] - u_pred[:, 1]) ** 2) + \\\n",
    "                torch.mean((self.u[:, 2] - u_pred[:, 2]) ** 2) + torch.mean((self.u[:, 3] - u_pred[:, 3]) ** 2) + \\\n",
    "                # torch.mean((rho_y_tb + u_y_tb + v_y_tb + p_y_tb) ** 2) + \\\n",
    "                # torch.mean((rho_x_lr + u_x_lr + v_x_lr + p_x_lr) ** 2) + \\\n",
    "                torch.mean(f_1_x ** 2) + torch.mean(f_2_x ** 2) + \\\n",
    "                torch.mean(f_1_y ** 2) + torch.mean(f_2_y ** 2)) + \\\n",
    "            (torch.mean(f_rho_pred ** 2) + torch.mean(f_u_pred ** 2) + \\\n",
    "                torch.mean(f_v_pred ** 2) + torch.mean(f_e_pred ** 2)) \n",
    "    \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        print('Loss: %e' % (loss.item()))\n",
    "        del u_pred, f_rho_pred, f_u_pred, f_v_pred, f_e_pred, f_1_x, f_2_x, f_1_y, f_2_y\n",
    "        return loss\n",
    "    \n",
    "    def train(self, nIter):\n",
    "        self.dnn.train()\n",
    "        # for epoch in range(nIter):\n",
    "        #     u_pred = self.net_u(self.x, self.y, self.t)\n",
    "        #     rho_y_tb, u_y_tb, v_y_tb, p_y_tb = self.net_f_y(self.x_tb, self.y_tb, self.t_tb)\n",
    "        #     rho_x_lr, u_x_lr, v_x_lr, p_x_lr = self.net_f_x(self.x_lr, self.y_lr, self.t_lr)\n",
    "        #     dx = 1/100\n",
    "        #     dy = 1/100\n",
    "        #     # loss_con = self.loss_con(self.x_en,self.x_in, self.y_en, self.y_in, 1,0,1,0.125,0,0.1,0.2)\n",
    "        #     f_rho_pred, f_u_pred, f_v_pred, f_e_pred, l = self.net_f(self.x_t, self.y_t, self.t_t)\n",
    "        #     f_1_x, f_2_x, f_1_y, f_2_y = self.net_f_rh(self.x_t, self.y_t, self.t_t, dx, dy)\n",
    "        #     loss = 10*(torch.mean((self.u[:, 0] - u_pred[:, 0]) ** 2) + torch.mean((self.u[:, 1] - u_pred[:, 1]) ** 2) + \\\n",
    "        #             torch.mean((self.u[:, 2] - u_pred[:, 2]) ** 2) + torch.mean((self.u[:, 3] - u_pred[:, 3]) ** 2) + \\\n",
    "        #             torch.mean((rho_y_tb + u_y_tb + v_y_tb + p_y_tb) ** 2) + \\\n",
    "        #             torch.mean((rho_x_lr + u_x_lr + v_x_lr + p_x_lr) ** 2) + \\\n",
    "        #             torch.mean(f_1_x ** 2) + torch.mean(f_2_x ** 2) + \\\n",
    "        #             torch.mean(f_1_y ** 2) + torch.mean(f_2_y ** 2)) + \\\n",
    "        #         (torch.mean(torch.mul(l, f_rho_pred) ** 2) + torch.mean(torch.mul(l, f_u_pred) ** 2) + \\\n",
    "        #          torch.mean(torch.mul(l, f_v_pred) ** 2) + torch.mean(torch.mul(l, f_e_pred) ** 2)) \n",
    "            \n",
    "        #     # Backward and optimize\n",
    "        #     self.optimizer_Adam.zero_grad()\n",
    "        #     loss.backward()\n",
    "        #     self.optimizer_Adam.step()\n",
    "            \n",
    "        #     if epoch % 100 == 0:\n",
    "        #         print(\n",
    "        #             'It: %d, Loss: %.3e' % \n",
    "        #             (\n",
    "        #                 epoch, \n",
    "        #                 loss.item(), \n",
    "        #             )\n",
    "        #         )\n",
    "        #     del u_pred, rho_y_tb, u_y_tb, v_y_tb, p_y_tb, rho_x_lr, u_x_lr, v_x_lr, p_x_lr, f_rho_pred, f_u_pred, f_v_pred, f_e_pred, f_1_x, f_2_x, f_1_y, f_2_y, l\n",
    "        self.optimizer.step(self.loss_func)\n",
    "                \n",
    "    \n",
    "    def predict(self, X):\n",
    "        x = torch.tensor(X[:, 0], requires_grad=True).float().to(device)\n",
    "        y = torch.tensor(X[:, 1], requires_grad=True).float().to(device)\n",
    "        t = torch.tensor(X[:, 2], requires_grad=True).float().to(device)\n",
    "        self.dnn.eval()\n",
    "        psi_and_p = self.net_u(x, y, t)\n",
    "        rho_pred = psi_and_p[:, 0]\n",
    "        u_pred = psi_and_p[:, 1]\n",
    "        v_pred = psi_and_p[:, 2]\n",
    "        p_pred = psi_and_p[:, 3]\n",
    "        return rho_pred, u_pred, v_pred, p_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [3, 50, 50, 50, 50, 50, 50, 50, 4]\n",
    "\n",
    "n = 101\n",
    "T = 21\n",
    "x = np.linspace(0, 1, n)\n",
    "y = np.linspace(0, 1, n)\n",
    "\n",
    "MG1 = np.meshgrid(x, y)\n",
    "xf = MG1[0].flatten()\n",
    "yf = MG1[1].flatten()\n",
    "\n",
    "X_test = np.vstack([xf, yf]).T      \n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = n*n\n",
    "\n",
    "\n",
    "xx = np.array(x).reshape(1, n)\n",
    "a = np.tile(xx, n).T\n",
    "\n",
    "yy = np.array(y).reshape(1, n)\n",
    "s = np.tile(yy.T, n).flatten()[None, :].T\n",
    "t = np.linspace(0, 0.4, T)\n",
    "f = t.reshape(1, T)\n",
    "t = t.reshape(-1)\n",
    "\n",
    "# Rearrange Data\n",
    "XX = np.tile(a, (1, T))  # N x T\n",
    "YY = np.tile(s, (1, T))  # N x T\n",
    "TT = np.tile(f, (N, 1))  # N x T\n",
    "\n",
    "xx = XX.flatten()[:, None]  # NT x 1\n",
    "yy = YY.flatten()[:, None]  # NT x 1\n",
    "tt = TT.flatten()[:, None]  # NT x 1\n",
    "\n",
    "X_test = np.hstack((xx, yy, tt))\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "u_it = []\n",
    "x_i = []\n",
    "wall = []\n",
    "x_lr = []\n",
    "x_tb = []\n",
    "x_ft = []\n",
    "x_it = []\n",
    "for i in range(len(X_test)):\n",
    "    if X_test[i][0] == 0 or X_test[i][0] == 1:\n",
    "          x_lr.append(X_test[i])\n",
    "    if X_test[i][1] == 0 or X_test[i][1] == 1:\n",
    "          x_tb.append(X_test[i])\n",
    "    if X_test[i][2] == 0.4:\n",
    "          x_ft.append(X_test[i])\n",
    "    if X_test[i][2] == 0:\n",
    "          x_it.append(X_test[i])\n",
    "\n",
    "# for i in range(len(x_it)):\n",
    "#     if x_it[i][0] > 0.8 and x_it[i][1] > 0.8:\n",
    "#         u_it.append([1.5, 0, 0, 1.5])\n",
    "#         x_i.append(x_it[i])\n",
    "#     elif x_it[i][0] <= 0.8 and x_it[i][1] > 0.8:\n",
    "#         u_it.append([33.0 / 62.0, 4.0 / math.sqrt(11.0), 0, 0.3])\n",
    "#         x_i.append(x_it[i])\n",
    "#     elif x_it[i][0] <= 0.8 and x_it[i][1] <= 0.8:\n",
    "#         u_it.append([77.0 / 558.0, 4.0 / math.sqrt(11.0), 4.0 / math.sqrt(11.0), 9.0 / 310.0])\n",
    "#         x_i.append(x_it[i])\n",
    "#     elif x_it[i][0] > 0.8 and x_it[i][1] <= 0.8:\n",
    "#         u_it.append([33.0 / 62.0, 0, 4.0 / math.sqrt(11.0), 0.3])\n",
    "#         x_i.append(x_it[i])\n",
    "          \n",
    "for i in range(len(x_it)):\n",
    "    if x_it[i][0] > 0.5 and x_it[i][1] > 0.5:\n",
    "        u_it.append([1, 0.75, -0.5, 1])\n",
    "        x_i.append(x_it[i])\n",
    "    elif x_it[i][0] <= 0.5 and x_it[i][1] > 0.5:\n",
    "        u_it.append([2, 0.75, 0.5, 1])\n",
    "        x_i.append(x_it[i])\n",
    "    elif x_it[i][0] <= 0.5 and x_it[i][1] <= 0.5:\n",
    "        u_it.append([1, -0.75, 0.5, 1])\n",
    "        x_i.append(x_it[i])\n",
    "    elif x_it[i][0] > 0.5 and x_it[i][1] <= 0.5:\n",
    "        u_it.append([3, -0.75, -0.5, 1])\n",
    "        x_i.append(x_it[i])\n",
    "\n",
    "x_i = np.array(x_i)\n",
    "u_i = np.array(u_it)\n",
    "x_tb = np.array(x_tb)\n",
    "x_lr = np.array(x_lr)\n",
    "x_ft = np.array(x_ft)\n",
    "x_it = np.array(x_it)\n",
    "\n",
    "X_i = np.vstack([x_i[:, 0], x_i[:, 1], x_i[:, 2]]).T\n",
    "X_tb = np.vstack([x_tb[:, 0], x_tb[:, 1], x_tb[:, 2]]).T\n",
    "X_lr = np.vstack([x_lr[:, 0], x_lr[:, 1], x_lr[:, 2]]).T\n",
    "U_i = np.vstack((u_i[:, 0], u_i[:, 1], u_i[:, 2], u_i[:, 3])).T \n",
    "X_it = np.vstack((x_it[:, 0], x_it[:, 1], x_it[:, 2])).T \n",
    "X_ft = np.vstack((x_ft[:, 0], x_ft[:, 1], x_it[:, 2])).T \n",
    "\n",
    "# fig = plt.figure(figsize = (10, 7))\n",
    "# ax = plt.axes(projection =\"3d\")\n",
    "# ax.scatter3D(X_u_train[:, 0], X_u_train[:, 1], u_train[:, 0], color = \"green\")\n",
    "# plt.title(\"simple 3D scatter plot\")\n",
    "\n",
    "plt.scatter(X_it[:, 0], X_it[:, 1], c =\"blue\", s = 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PhysicsInformedNN(X_i, U_i, X_test, X_tb, X_lr, layers)\n",
    "model.train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_pred, u_pred, v_pred, p_pred = model.predict(X_test)\n",
    "preds =  torch.stack([rho_pred, u_pred, v_pred, p_pred], dim=1)\n",
    "preds = preds.detach().cpu().numpy()\n",
    "rho_pred = preds[:, 0]\n",
    "u_pred = preds[:, 1]\n",
    "v_pred = preds[:, 2]\n",
    "p_pred = preds[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 101\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "con_lv = 120\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "_u = u_pred.reshape(n, n, 21)\n",
    "contour1 = ax1.contourf(_u[:, :, 20], con_lv, origin='lower', cmap='rainbow', aspect='auto')\n",
    "ax1.set_aspect('equal')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('[u_pred]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "_p = p_pred.reshape(n ,n, 40)\n",
    "contour1 = ax1.contourf(_p[:, :, 19], con_lv, origin='lower', cmap='rainbow', aspect='auto')\n",
    "ax1.set_aspect('equal')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('[p_pred]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "_V = rho_pred.reshape(n, n)\n",
    "contour1 = ax1.contourf(_V, con_lv, origin='lower', cmap='rainbow', aspect='auto')\n",
    "ax1.set_aspect('equal')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('[v_mag_p]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('PINN_TORCH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "957e5d627425778360898b4af626d5bac49c7f588b606639c6ebacd098566aea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
